{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "import os\n",
    "from PIL import Image\n",
    "from scipy.fftpack import dct\n",
    "from scipy.fftpack import idct\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the watermarking algorithm for video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wavelet Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet_tf(imArray, model, level):\n",
    "    coeffs=pywt.wavedec2(data = imArray, wavelet = model, level = level)\n",
    "    # print coeffs[0].__len__()\n",
    "    coeffs_H=list(coeffs) \n",
    "   \n",
    "    return coeffs_H\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embed Watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_watermark(watermark_array, orig_image):\n",
    "    watermark_array_size = watermark_array[0].__len__() # Gets the size of the watermark array\n",
    "    watermark_flat = watermark_array.ravel() # Flattens the watermark array\n",
    "    ind = 0\n",
    "\n",
    "    for x in range (0, orig_image.__len__(), 8): # Loops through the image in 8x8 blocks\n",
    "        for y in range (0, orig_image.__len__(), 8):\n",
    "            if ind < watermark_flat.__len__(): # While in the watermark array size\n",
    "                subdct = orig_image[x:x+8, y:y+8] # Gets the 8x8 block of the image\n",
    "                subdct[5][5] = watermark_flat[ind] # Sets the 5,5 value of the block to the watermark value\n",
    "                orig_image[x:x+8, y:y+8] = subdct # Sets the 8x8 block of the image to the new block\n",
    "                ind += 1 # Next Watermark's pixel value\n",
    "\n",
    "\n",
    "    return orig_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why 8x8 blocks ? Maybe so that the compression (by block) alters less of the watermark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DCT Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_dct(image_array): # Applies the DCT to each 8x8 block of the image\n",
    "    size = image_array[0].__len__()\n",
    "    all_subdct = np.empty((size, size))\n",
    "    for i in range (0, size, 8):\n",
    "        for j in range (0, size, 8):\n",
    "            subpixels = image_array[i:i+8, j:j+8]\n",
    "            subdct = dct(dct(subpixels.T, norm=\"ortho\").T, norm=\"ortho\")\n",
    "            all_subdct[i:i+8, j:j+8] = subdct\n",
    "\n",
    "    return all_subdct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_dct(all_subdct):\n",
    "    size = all_subdct[0].__len__()\n",
    "    all_subidct = np.empty((size, size))\n",
    "    for i in range (0, size, 8):\n",
    "        for j in range (0, size, 8):\n",
    "            subidct = idct(idct(all_subdct[i:i+8, j:j+8].T, norm=\"ortho\").T, norm=\"ortho\")\n",
    "            all_subidct[i:i+8, j:j+8] = subidct\n",
    "\n",
    "    return all_subidct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve the watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_watermark(dct_watermarked_coeff, watermark_size): \n",
    "    # Gets the [5,5] coefficient of each 8x8 block of the watermarked image and puts it into a 1D array\n",
    "    \n",
    "    subwatermarks = []\n",
    "\n",
    "    for x in range (0, dct_watermarked_coeff.__len__(), 8):\n",
    "        for y in range (0, dct_watermarked_coeff.__len__(), 8):\n",
    "            coeff_slice = dct_watermarked_coeff[x:x+8, y:y+8]\n",
    "            subwatermarks.append(coeff_slice[5][5])\n",
    "\n",
    "    watermark = np.array(subwatermarks).reshape(watermark_size, watermark_size)\n",
    "    #Reshapes the flattened array into a 2D array\n",
    "    return watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_watermark(image_array, model='haar', level = 1):\n",
    "\n",
    "\n",
    "    coeffs_watermarked_image = process_coefficients(image_array, model, level=level)\n",
    "    dct_watermarked_coeff = apply_dct(coeffs_watermarked_image[0])\n",
    "    \n",
    "    watermark_array = get_watermark(dct_watermarked_coeff, 128)\n",
    "\n",
    "    watermark_array =  np.uint8(watermark_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the algorithm on a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watermark = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def watermark_image(img):\n",
    "    model = 'haar'\n",
    "    level = 1\n",
    "    image_array = convert_image(image, 2048)\n",
    "    watermark_array = convert_image(watermark, 128)\n",
    "\n",
    "    coeffs_image = process_coefficients(image_array, model, level=level)\n",
    "    dct_array = apply_dct(coeffs_image[0])\n",
    "    dct_array = embed_watermark(watermark_array, dct_array)\n",
    "    coeffs_image[0] = inverse_dct(dct_array)\n",
    "  \n",
    "    image_array_H=pywt.waverec2(coeffs_image, model)\n",
    "\n",
    "    recover_watermark(image_array = image_array_H, model=model, level = level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('oppenheimer_trailer.mp4')\n",
    "total_frames = last_frame_number = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "frame_number = -1\n",
    "while True:\n",
    "    frame_number += 1\n",
    "    cap.set(1, frame_number)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret or frame_number >= last_frame_number:\n",
    "        break\n",
    "\n",
    "    # Modify the pixels of the frame here\n",
    "    # For example, convert the frame to grayscale\n",
    "    watermarked_image = watermark_image(frame)\n",
    "\n",
    "    # Write the modified frame to a new video file\n",
    "    out.write(gray_frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
